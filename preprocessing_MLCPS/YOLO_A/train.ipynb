{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING\n",
    "# - For YOLO training, ensure the data and labels are arranged in the following specific folder structure:\n",
    "#   yolo_A/\n",
    "#     - data/\n",
    "#         - images/\n",
    "#             - train/\n",
    "#             - val/\n",
    "#         - labels/\n",
    "#             - train/\n",
    "#             - val/\n",
    "# - Also, make sure to update the paths in the `config.yaml` file accordingly.\n",
    "# - Add the path of the `config.yaml` here in the training script for proper configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.6 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.103 ðŸš€ Python-3.12.2 torch-2.4.1+cu121 CPU (13th Gen Intel Core(TM) i9-13900K)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Preprocessing_MLCPS/yolo_A/config.yaml, epochs=40, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train3\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train3', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Preprocessing_MLCPS/yolo_A/data/labels/train.cache... 100 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<?, ?it/s]\n",
      "/home/jai/miniconda3/lib/python3.12/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Preprocessing_MLCPS/yolo_A/data/labels/val.cache... 10 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train3/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train3\u001b[0m\n",
      "Starting training for 40 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/40         0G       1.22      2.563      1.646         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:15<00:00,  2.15s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         10      0.003        0.9      0.402      0.179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/40         0G      1.131       2.08      1.517         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:12<00:00,  1.83s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         10    0.00267        0.8      0.411      0.263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/40         0G      1.078      1.683      1.492         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:13<00:00,  1.94s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         10     0.0409        0.3      0.252     0.0437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/40         0G      1.058      1.464      1.448         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:12<00:00,  1.82s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         10          1      0.198        0.2     0.0673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/40         0G      1.071      1.441      1.445         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:13<00:00,  1.91s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         10      0.956        0.4        0.4     0.0912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/40         0G       1.04      1.384      1.448         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:12<00:00,  1.83s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         10      0.619        0.2      0.231     0.0628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/40         0G      1.059       1.43      1.445         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:12<00:00,  1.79s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         10      0.434      0.234       0.34      0.164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/40         0G      1.128      1.359      1.425         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:13<00:00,  1.92s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         10      0.222        0.3      0.113      0.044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/40         0G      1.023      1.245      1.385         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:13<00:00,  1.93s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         10      0.183        0.5      0.158     0.0696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/40         0G      1.018      1.187      1.356         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:12<00:00,  1.82s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         10      0.288        0.3      0.215      0.112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/40         0G     0.9355      1.168      1.343         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:13<00:00,  1.90s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         10      0.187        0.4      0.168     0.0663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/40         0G       1.02      1.229       1.37         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:13<00:00,  1.93s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         10      0.483        0.4      0.252     0.0331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/40         0G      1.069       1.22      1.446         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:12<00:00,  1.84s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         10      0.331        0.5      0.307      0.128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/40         0G     0.9651      1.153      1.324         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:13<00:00,  1.88s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         10      0.621        0.4      0.368       0.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/40         0G     0.9754      1.138      1.357         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:13<00:00,  1.92s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         10      0.548      0.486       0.33       0.21\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      16/40         0G      1.044      1.152      1.382         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:13<00:00,  1.95s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         10      0.913        0.2      0.272      0.176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/40         0G     0.9673      1.038      1.309         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:13<00:00,  1.91s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         10      0.335        0.3      0.225      0.136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/40         0G       1.11      1.112      1.411         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:13<00:00,  1.92s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         10      0.571        0.3      0.322      0.147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/40         0G      1.011      1.163       1.39         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:13<00:00,  1.93s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         10      0.966        0.2      0.268       0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/40         0G     0.9879      1.068      1.341         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:14<00:00,  2.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         10      0.477        0.2      0.143     0.0708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/40         0G     0.9682      1.044      1.359         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:12<00:00,  1.82s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         10      0.485      0.285      0.232      0.113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/40         0G     0.9533     0.9942      1.282         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:13<00:00,  1.94s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         10      0.955        0.3      0.333      0.219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/40         0G     0.9779      1.065      1.339         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:13<00:00,  1.89s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         10        0.5        0.3      0.251      0.151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/40         0G     0.8708     0.9179      1.241         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:13<00:00,  1.89s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         10      0.717        0.3      0.356      0.277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/40         0G     0.8768     0.8988      1.265         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:12<00:00,  1.85s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         10      0.622        0.3      0.385      0.244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/40         0G     0.8627     0.9053      1.272         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:13<00:00,  1.92s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         10      0.585        0.3      0.357      0.204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/40         0G     0.8633     0.8995      1.239         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:12<00:00,  1.84s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         10      0.685        0.3      0.317       0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/40         0G     0.7761     0.8284      1.199         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:13<00:00,  1.89s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         10      0.731        0.3      0.318      0.233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/40         0G     0.8071     0.8358      1.199         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:13<00:00,  1.92s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         10       0.73        0.3      0.303      0.196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/40         0G     0.7992     0.8655      1.204         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:12<00:00,  1.83s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         10      0.359        0.6      0.365      0.223\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      31/40         0G     0.8459      1.185      1.382          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         10      0.453        0.5      0.444      0.282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/40         0G     0.6885     0.9338        1.2          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         10      0.917        0.3      0.446      0.282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/40         0G     0.6613     0.8906      1.142          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         10      0.926        0.3      0.423      0.272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/40         0G     0.7684     0.9093      1.224          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         10      0.842        0.3      0.427      0.278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/40         0G     0.7517     0.8577      1.249          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         10      0.349        0.6      0.431      0.274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/40         0G     0.6277      0.754      1.172          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         10      0.784        0.3      0.419      0.282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/40         0G     0.6756     0.8151      1.131          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         10      0.844        0.3      0.405      0.271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/40         0G     0.6391     0.7632      1.125          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         10       0.83        0.3      0.399      0.278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/40         0G     0.6015     0.7493      1.107          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         10      0.928        0.3      0.411       0.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/40         0G     0.6851     0.7989      1.181          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         10      0.966        0.3       0.42       0.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "40 epochs completed in 0.135 hours.\n",
      "Optimizer stripped from runs/detect/train3/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from runs/detect/train3/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating runs/detect/train3/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.103 ðŸš€ Python-3.12.2 torch-2.4.1+cu121 CPU (13th Gen Intel Core(TM) i9-13900K)\n",
      "Model summary (fused): 168 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         10         10      0.965        0.3       0.42       0.29\n",
      "Speed: 0.3ms preprocess, 11.9ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained YOLOv8 \n",
    "model = YOLO(\"yolov8n.pt\")  # Load pre-trained model\n",
    "\n",
    "# Fine-tune the model on your custom dataset\n",
    "results = model.train(data=\"............/yolo_A/config.yaml\", epochs=40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICTION ON TRAIN DATA TO REMOVE OUTLIERS\n",
    "# - This step will predict on the training data and remove outliers.\n",
    "# - Images without outliers will be saved in a separate folder for further use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/79_A.jpg: 480x640 1 A, 31.0ms\n",
      "Speed: 1.2ms preprocess, 31.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/79_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/158_A.jpg: 480x640 3 As, 14.9ms\n",
      "Speed: 1.2ms preprocess, 14.9ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/158_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/144_A.jpg: 480x640 1 A, 12.7ms\n",
      "Speed: 0.6ms preprocess, 12.7ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/144_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/56_A.jpg: 480x640 1 A, 12.6ms\n",
      "Speed: 0.6ms preprocess, 12.6ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/56_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/120_A.jpg: 480x640 2 As, 26.0ms\n",
      "Speed: 1.2ms preprocess, 26.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/120_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/212_A.jpg: 480x640 1 A, 25.9ms\n",
      "Speed: 1.2ms preprocess, 25.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/212_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/114_A.jpg: 480x640 3 As, 25.6ms\n",
      "Speed: 1.2ms preprocess, 25.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/114_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/255_A.jpg: 480x640 3 As, 12.5ms\n",
      "Speed: 1.0ms preprocess, 12.5ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/255_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/209_A.jpg: 480x640 1 A, 12.5ms\n",
      "Speed: 0.6ms preprocess, 12.5ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/209_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/207_A.jpg: 480x640 (no detections), 12.5ms\n",
      "Speed: 0.6ms preprocess, 12.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No detection found for image: 207_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/1_A.jpg: 480x640 2 As, 26.1ms\n",
      "Speed: 1.2ms preprocess, 26.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/1_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/141_A.jpg: 480x640 2 As, 12.5ms\n",
      "Speed: 0.8ms preprocess, 12.5ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/141_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/170_A.jpg: 480x640 3 As, 12.6ms\n",
      "Speed: 0.6ms preprocess, 12.6ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/170_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/137_A.jpg: 480x640 1 A, 12.5ms\n",
      "Speed: 0.6ms preprocess, 12.5ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/137_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/198_A.jpg: 480x640 1 A, 25.9ms\n",
      "Speed: 1.2ms preprocess, 25.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/198_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/232_A.jpg: 480x640 1 A, 12.6ms\n",
      "Speed: 0.6ms preprocess, 12.6ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No boxes with confidence > 0.5 for image: 232_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/249_A.jpg: 480x640 (no detections), 12.6ms\n",
      "Speed: 0.6ms preprocess, 12.6ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No detection found for image: 249_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/278_A.jpg: 480x640 2 As, 12.6ms\n",
      "Speed: 0.6ms preprocess, 12.6ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/278_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/105_A.jpg: 480x640 1 A, 11.9ms\n",
      "Speed: 0.6ms preprocess, 11.9ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/105_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/159_A.jpg: 480x640 1 A, 11.9ms\n",
      "Speed: 0.6ms preprocess, 11.9ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No boxes with confidence > 0.5 for image: 159_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/227_A.jpg: 480x640 (no detections), 26.0ms\n",
      "Speed: 1.2ms preprocess, 26.0ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No detection found for image: 227_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/213_A.jpg: 480x640 (no detections), 18.8ms\n",
      "Speed: 1.2ms preprocess, 18.8ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No detection found for image: 213_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/244_A.jpg: 480x640 (no detections), 25.5ms\n",
      "Speed: 1.2ms preprocess, 25.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No detection found for image: 244_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/239_A.jpg: 480x640 (no detections), 25.9ms\n",
      "Speed: 1.2ms preprocess, 25.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No detection found for image: 239_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/297_A.jpg: 480x640 2 As, 12.2ms\n",
      "Speed: 0.6ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/297_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/296_A.jpg: 480x640 4 As, 12.3ms\n",
      "Speed: 0.7ms preprocess, 12.3ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/296_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/277_A.jpg: 480x640 1 A, 12.3ms\n",
      "Speed: 0.6ms preprocess, 12.3ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/277_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/197_A.jpg: 480x640 1 A, 12.6ms\n",
      "Speed: 0.6ms preprocess, 12.6ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/197_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/157_A.jpg: 480x640 4 As, 12.3ms\n",
      "Speed: 0.7ms preprocess, 12.3ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/157_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/216_A.jpg: 480x640 2 As, 12.4ms\n",
      "Speed: 0.6ms preprocess, 12.4ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/216_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/139_A.jpg: 480x640 1 A, 12.4ms\n",
      "Speed: 0.6ms preprocess, 12.4ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No boxes with confidence > 0.5 for image: 139_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/39_A.jpg: 480x640 1 A, 26.0ms\n",
      "Speed: 1.2ms preprocess, 26.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/39_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/37_A.jpg: 480x640 2 As, 12.1ms\n",
      "Speed: 1.0ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/37_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/257_A.jpg: 480x640 2 As, 12.2ms\n",
      "Speed: 0.6ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/257_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/72_A.jpg: 480x640 1 A, 12.2ms\n",
      "Speed: 0.6ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/72_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/67_A.jpg: 480x640 1 A, 26.0ms\n",
      "Speed: 1.2ms preprocess, 26.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/67_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/182_A.jpg: 480x640 1 A, 12.2ms\n",
      "Speed: 0.6ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No boxes with confidence > 0.5 for image: 182_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/25_A.jpg: 480x640 3 As, 12.2ms\n",
      "Speed: 0.6ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/25_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/12_A.jpg: 480x640 2 As, 12.2ms\n",
      "Speed: 0.6ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/12_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/85_A.jpg: 480x640 2 As, 25.9ms\n",
      "Speed: 1.2ms preprocess, 25.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/85_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/264_A.jpg: 480x640 1 A, 12.2ms\n",
      "Speed: 0.6ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/264_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/163_A.jpg: 480x640 3 As, 12.2ms\n",
      "Speed: 0.6ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/163_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/151_A.jpg: 480x640 2 As, 12.2ms\n",
      "Speed: 0.6ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/151_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/116_A.jpg: 480x640 2 As, 12.2ms\n",
      "Speed: 0.6ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/116_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/181_A.jpg: 480x640 1 A, 26.0ms\n",
      "Speed: 1.2ms preprocess, 26.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No boxes with confidence > 0.5 for image: 181_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/87_A.jpg: 480x640 2 As, 14.5ms\n",
      "Speed: 1.2ms preprocess, 14.5ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/87_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/230_A.jpg: 480x640 (no detections), 12.3ms\n",
      "Speed: 0.6ms preprocess, 12.3ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No detection found for image: 230_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/266_A.jpg: 480x640 3 As, 12.2ms\n",
      "Speed: 0.6ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No boxes with confidence > 0.5 for image: 266_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/178_A.jpg: 480x640 2 As, 26.0ms\n",
      "Speed: 1.2ms preprocess, 26.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/178_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/218_A.jpg: 480x640 1 A, 12.2ms\n",
      "Speed: 0.6ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No boxes with confidence > 0.5 for image: 218_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/109_A.jpg: 480x640 (no detections), 12.2ms\n",
      "Speed: 0.6ms preprocess, 12.2ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No detection found for image: 109_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/119_A.jpg: 480x640 2 As, 12.1ms\n",
      "Speed: 0.6ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/119_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/246_A.jpg: 480x640 1 A, 12.2ms\n",
      "Speed: 0.6ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No boxes with confidence > 0.5 for image: 246_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/294_A.jpg: 480x640 1 A, 26.0ms\n",
      "Speed: 1.2ms preprocess, 26.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/294_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/82_A.jpg: 480x640 1 A, 12.2ms\n",
      "Speed: 0.6ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/82_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/261_A.jpg: 480x640 2 As, 12.2ms\n",
      "Speed: 0.7ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/261_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/17_A.jpg: 480x640 1 A, 12.2ms\n",
      "Speed: 0.6ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/17_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/204_A.jpg: 480x640 2 As, 12.2ms\n",
      "Speed: 0.6ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/204_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/69_A.jpg: 480x640 2 As, 12.2ms\n",
      "Speed: 0.6ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/69_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/59_A.jpg: 480x640 1 A, 26.0ms\n",
      "Speed: 1.2ms preprocess, 26.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/59_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/76_A.jpg: 480x640 1 A, 25.7ms\n",
      "Speed: 1.2ms preprocess, 25.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No boxes with confidence > 0.5 for image: 76_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/270_A.jpg: 480x640 2 As, 12.2ms\n",
      "Speed: 1.2ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/270_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/77_A.jpg: 480x640 3 As, 12.2ms\n",
      "Speed: 0.6ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/77_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/147_A.jpg: 480x640 1 A, 12.2ms\n",
      "Speed: 0.6ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/147_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/92_A.jpg: 480x640 1 A, 25.9ms\n",
      "Speed: 1.2ms preprocess, 25.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/92_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/152_A.jpg: 480x640 1 A, 12.2ms\n",
      "Speed: 0.6ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/152_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/200_A.jpg: 480x640 1 A, 12.3ms\n",
      "Speed: 0.6ms preprocess, 12.3ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/200_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/47_A.jpg: 480x640 1 A, 12.2ms\n",
      "Speed: 0.6ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/47_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/86_A.jpg: 480x640 2 As, 12.2ms\n",
      "Speed: 0.6ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/86_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/236_A.jpg: 480x640 1 A, 26.0ms\n",
      "Speed: 1.2ms preprocess, 26.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No boxes with confidence > 0.5 for image: 236_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/248_A.jpg: 480x640 1 A, 12.3ms\n",
      "Speed: 0.6ms preprocess, 12.3ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/248_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/150_A.jpg: 480x640 2 As, 12.2ms\n",
      "Speed: 0.6ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/150_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/211_A.jpg: 480x640 2 As, 12.2ms\n",
      "Speed: 0.6ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/211_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/265_A.jpg: 480x640 1 A, 25.9ms\n",
      "Speed: 1.2ms preprocess, 25.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/265_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/253_A.jpg: 480x640 2 As, 25.7ms\n",
      "Speed: 1.2ms preprocess, 25.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/253_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/155_A.jpg: 480x640 2 As, 25.6ms\n",
      "Speed: 1.2ms preprocess, 25.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/155_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/228_A.jpg: 480x640 (no detections), 13.8ms\n",
      "Speed: 1.2ms preprocess, 13.8ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No detection found for image: 228_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/49_A.jpg: 480x640 2 As, 12.2ms\n",
      "Speed: 0.6ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/49_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/36_A.jpg: 480x640 2 As, 12.4ms\n",
      "Speed: 0.6ms preprocess, 12.4ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/36_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/166_A.jpg: 480x640 1 A, 26.0ms\n",
      "Speed: 1.2ms preprocess, 26.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/166_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/66_A.jpg: 480x640 1 A, 12.2ms\n",
      "Speed: 0.6ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No boxes with confidence > 0.5 for image: 66_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/65_A.jpg: 480x640 3 As, 12.5ms\n",
      "Speed: 0.6ms preprocess, 12.5ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/65_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/28_A.jpg: 480x640 2 As, 12.2ms\n",
      "Speed: 0.6ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/28_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/43_A.jpg: 480x640 1 A, 26.0ms\n",
      "Speed: 1.2ms preprocess, 26.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/43_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/113_A.jpg: 480x640 4 As, 15.1ms\n",
      "Speed: 1.2ms preprocess, 15.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/113_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/20_A.jpg: 480x640 2 As, 12.2ms\n",
      "Speed: 0.6ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/20_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/140_A.jpg: 480x640 (no detections), 12.2ms\n",
      "Speed: 0.6ms preprocess, 12.2ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No detection found for image: 140_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/229_A.jpg: 480x640 1 A, 12.2ms\n",
      "Speed: 0.6ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No boxes with confidence > 0.5 for image: 229_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/217_A.jpg: 480x640 1 A, 26.0ms\n",
      "Speed: 1.2ms preprocess, 26.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/217_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/61_A.jpg: 480x640 1 A, 12.2ms\n",
      "Speed: 0.8ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/61_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/142_A.jpg: 480x640 2 As, 12.2ms\n",
      "Speed: 0.6ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/142_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/11_A.jpg: 480x640 2 As, 12.2ms\n",
      "Speed: 0.6ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/11_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/242_A.jpg: 480x640 2 As, 12.2ms\n",
      "Speed: 0.6ms preprocess, 12.2ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/242_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/298_A.jpg: 480x640 2 As, 12.2ms\n",
      "Speed: 0.6ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/298_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/57_A.jpg: 480x640 1 A, 12.2ms\n",
      "Speed: 0.6ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/57_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/262_A.jpg: 480x640 2 As, 26.0ms\n",
      "Speed: 1.2ms preprocess, 26.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/262_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/15_A.jpg: 480x640 2 As, 25.7ms\n",
      "Speed: 1.2ms preprocess, 25.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/15_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/238_A.jpg: 480x640 (no detections), 12.2ms\n",
      "Speed: 0.6ms preprocess, 12.2ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No detection found for image: 238_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/128_A.jpg: 480x640 2 As, 12.2ms\n",
      "Speed: 0.6ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No boxes with confidence > 0.5 for image: 128_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/60_A.jpg: 480x640 3 As, 12.2ms\n",
      "Speed: 0.6ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/60_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/96_A.jpg: 480x640 1 A, 26.0ms\n",
      "Speed: 1.2ms preprocess, 26.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/96_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/276_A.jpg: 480x640 2 As, 12.2ms\n",
      "Speed: 0.6ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/276_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/193_A.jpg: 480x640 3 As, 19.2ms\n",
      "Speed: 1.2ms preprocess, 19.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/193_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/154_A.jpg: 480x640 3 As, 12.3ms\n",
      "Speed: 0.6ms preprocess, 12.3ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/154_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/108_A.jpg: 480x640 1 A, 14.8ms\n",
      "Speed: 0.6ms preprocess, 14.8ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No boxes with confidence > 0.5 for image: 108_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/231_A.jpg: 480x640 (no detections), 14.1ms\n",
      "Speed: 0.7ms preprocess, 14.1ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No detection found for image: 231_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/21_A.jpg: 480x640 3 As, 12.2ms\n",
      "Speed: 0.6ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/21_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/233_A.jpg: 480x640 (no detections), 13.2ms\n",
      "Speed: 0.6ms preprocess, 13.2ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No detection found for image: 233_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/94_A.jpg: 480x640 2 As, 21.4ms\n",
      "Speed: 1.2ms preprocess, 21.4ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/94_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/27_A.jpg: 480x640 3 As, 20.9ms\n",
      "Speed: 0.7ms preprocess, 20.9ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/27_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/117_A.jpg: 480x640 2 As, 24.5ms\n",
      "Speed: 1.2ms preprocess, 24.5ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/117_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/186_A.jpg: 480x640 (no detections), 20.5ms\n",
      "Speed: 0.9ms preprocess, 20.5ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No detection found for image: 186_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/162_A.jpg: 480x640 3 As, 12.1ms\n",
      "Speed: 0.6ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/162_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/252_A.jpg: 480x640 2 As, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No boxes with confidence > 0.5 for image: 252_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/273_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/273_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/132_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/132_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/160_A.jpg: 480x640 2 As, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/160_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/180_A.jpg: 480x640 2 As, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/180_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/83_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/83_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/287_A.jpg: 480x640 3 As, 26.0ms\n",
      "Speed: 1.2ms preprocess, 26.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/287_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/81_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.9ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/81_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/99_A.jpg: 480x640 2 As, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/99_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/101_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No boxes with confidence > 0.5 for image: 101_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/177_A.jpg: 480x640 2 As, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/177_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/263_A.jpg: 480x640 1 A, 25.9ms\n",
      "Speed: 1.2ms preprocess, 25.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/263_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/135_A.jpg: 480x640 4 As, 25.6ms\n",
      "Speed: 1.2ms preprocess, 25.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/135_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/164_A.jpg: 480x640 (no detections), 12.0ms\n",
      "Speed: 0.7ms preprocess, 12.0ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No detection found for image: 164_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/295_A.jpg: 480x640 2 As, 11.9ms\n",
      "Speed: 0.6ms preprocess, 11.9ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/295_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/10_A.jpg: 480x640 2 As, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/10_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/50_A.jpg: 480x640 1 A, 25.9ms\n",
      "Speed: 1.2ms preprocess, 25.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/50_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/95_A.jpg: 480x640 1 A, 12.2ms\n",
      "Speed: 1.2ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/95_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/268_A.jpg: 480x640 1 A, 20.4ms\n",
      "Speed: 1.1ms preprocess, 20.4ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/268_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/126_A.jpg: 480x640 1 A, 12.1ms\n",
      "Speed: 0.6ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No boxes with confidence > 0.5 for image: 126_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/221_A.jpg: 480x640 1 A, 12.3ms\n",
      "Speed: 0.6ms preprocess, 12.3ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/221_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/258_A.jpg: 480x640 2 As, 25.9ms\n",
      "Speed: 1.2ms preprocess, 25.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/258_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/9_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/9_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/6_A.jpg: 480x640 3 As, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/6_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/285_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/285_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/173_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/173_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/7_A.jpg: 480x640 3 As, 25.9ms\n",
      "Speed: 1.2ms preprocess, 25.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/7_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/22_A.jpg: 480x640 2 As, 12.1ms\n",
      "Speed: 0.9ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/22_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/175_A.jpg: 480x640 2 As, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/175_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/45_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/45_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/93_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/93_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/134_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/134_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/206_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/206_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/243_A.jpg: 480x640 1 A, 26.1ms\n",
      "Speed: 1.2ms preprocess, 26.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/243_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/110_A.jpg: 480x640 (no detections), 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No detection found for image: 110_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/48_A.jpg: 480x640 2 As, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/48_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/149_A.jpg: 480x640 2 As, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/149_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/98_A.jpg: 480x640 1 A, 25.9ms\n",
      "Speed: 1.2ms preprocess, 25.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/98_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/24_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/24_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/203_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No boxes with confidence > 0.5 for image: 203_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/185_A.jpg: 480x640 1 A, 12.1ms\n",
      "Speed: 0.6ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/185_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/275_A.jpg: 480x640 3 As, 25.9ms\n",
      "Speed: 1.2ms preprocess, 25.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/275_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/130_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/130_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/33_A.jpg: 480x640 3 As, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/33_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/187_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No boxes with confidence > 0.5 for image: 187_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/293_A.jpg: 480x640 3 As, 13.4ms\n",
      "Speed: 1.2ms preprocess, 13.4ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/293_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/291_A.jpg: 480x640 2 As, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/291_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/13_A.jpg: 480x640 2 As, 26.0ms\n",
      "Speed: 1.2ms preprocess, 26.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/13_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/100_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/100_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/289_A.jpg: 480x640 2 As, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/289_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/267_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/267_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/75_A.jpg: 480x640 2 As, 25.9ms\n",
      "Speed: 1.2ms preprocess, 25.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/75_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/251_A.jpg: 480x640 1 A, 26.4ms\n",
      "Speed: 1.2ms preprocess, 26.4ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/251_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/196_A.jpg: 480x640 1 A, 25.6ms\n",
      "Speed: 1.2ms preprocess, 25.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/196_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/35_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 1.1ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/35_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/240_A.jpg: 480x640 (no detections), 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No detection found for image: 240_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/195_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/195_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/106_A.jpg: 480x640 (no detections), 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No detection found for image: 106_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/129_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/129_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/68_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/68_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/121_A.jpg: 480x640 4 As, 12.2ms\n",
      "Speed: 0.6ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/121_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/208_A.jpg: 480x640 2 As, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/208_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/191_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/191_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/89_A.jpg: 480x640 2 As, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/89_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/183_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No boxes with confidence > 0.5 for image: 183_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/205_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/205_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/241_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/241_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/30_A.jpg: 480x640 1 A, 26.0ms\n",
      "Speed: 1.2ms preprocess, 26.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/30_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/274_A.jpg: 480x640 2 As, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/274_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/280_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No boxes with confidence > 0.5 for image: 280_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/16_A.jpg: 480x640 2 As, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/16_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/26_A.jpg: 480x640 2 As, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/26_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/250_A.jpg: 480x640 1 A, 25.9ms\n",
      "Speed: 1.2ms preprocess, 25.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No boxes with confidence > 0.5 for image: 250_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/288_A.jpg: 480x640 2 As, 12.1ms\n",
      "Speed: 0.8ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/288_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/18_A.jpg: 480x640 1 A, 12.1ms\n",
      "Speed: 0.6ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/18_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/97_A.jpg: 480x640 1 A, 12.1ms\n",
      "Speed: 0.6ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/97_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/281_A.jpg: 480x640 (no detections), 26.0ms\n",
      "Speed: 1.2ms preprocess, 26.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No detection found for image: 281_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/210_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.8ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/210_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/118_A.jpg: 480x640 2 As, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/118_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/40_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/40_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/176_A.jpg: 480x640 2 As, 12.1ms\n",
      "Speed: 0.6ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/176_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/3_A.jpg: 480x640 1 A, 25.9ms\n",
      "Speed: 1.2ms preprocess, 25.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/3_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/172_A.jpg: 480x640 2 As, 12.1ms\n",
      "Speed: 0.9ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/172_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/283_A.jpg: 480x640 2 As, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No boxes with confidence > 0.5 for image: 283_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/214_A.jpg: 480x640 (no detections), 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No detection found for image: 214_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/138_A.jpg: 480x640 (no detections), 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No detection found for image: 138_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/63_A.jpg: 480x640 1 A, 26.0ms\n",
      "Speed: 1.2ms preprocess, 26.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/63_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/234_A.jpg: 480x640 (no detections), 12.0ms\n",
      "Speed: 0.8ms preprocess, 12.0ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No detection found for image: 234_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/14_A.jpg: 480x640 2 As, 12.1ms\n",
      "Speed: 0.6ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/14_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/123_A.jpg: 480x640 1 A, 12.1ms\n",
      "Speed: 0.6ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/123_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/136_A.jpg: 480x640 2 As, 25.9ms\n",
      "Speed: 1.2ms preprocess, 25.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/136_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/254_A.jpg: 480x640 2 As, 25.7ms\n",
      "Speed: 1.2ms preprocess, 25.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/254_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/58_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/58_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/224_A.jpg: 480x640 1 A, 12.1ms\n",
      "Speed: 0.6ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/224_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/259_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/259_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/124_A.jpg: 480x640 1 A, 25.9ms\n",
      "Speed: 1.2ms preprocess, 25.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/124_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/70_A.jpg: 480x640 1 A, 12.3ms\n",
      "Speed: 1.2ms preprocess, 12.3ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/70_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/279_A.jpg: 480x640 (no detections), 12.1ms\n",
      "Speed: 0.6ms preprocess, 12.1ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No detection found for image: 279_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/125_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No boxes with confidence > 0.5 for image: 125_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/189_A.jpg: 480x640 1 A, 23.6ms\n",
      "Speed: 1.2ms preprocess, 23.6ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No boxes with confidence > 0.5 for image: 189_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/286_A.jpg: 480x640 2 As, 13.2ms\n",
      "Speed: 1.2ms preprocess, 13.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/286_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/194_A.jpg: 480x640 1 A, 12.1ms\n",
      "Speed: 0.6ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/194_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/64_A.jpg: 480x640 2 As, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/64_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/38_A.jpg: 480x640 1 A, 25.8ms\n",
      "Speed: 1.2ms preprocess, 25.8ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/38_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/90_A.jpg: 480x640 3 As, 12.1ms\n",
      "Speed: 0.6ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/90_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/153_A.jpg: 480x640 2 As, 12.1ms\n",
      "Speed: 0.6ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/153_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/226_A.jpg: 480x640 (no detections), 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No detection found for image: 226_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/73_A.jpg: 480x640 3 As, 12.1ms\n",
      "Speed: 1.2ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/73_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/256_A.jpg: 480x640 1 A, 12.1ms\n",
      "Speed: 0.6ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/256_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/88_A.jpg: 480x640 2 As, 12.1ms\n",
      "Speed: 0.6ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/88_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/145_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/145_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/131_A.jpg: 480x640 2 As, 11.9ms\n",
      "Speed: 0.6ms preprocess, 11.9ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/131_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/282_A.jpg: 480x640 2 As, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/282_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/74_A.jpg: 480x640 2 As, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/74_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/237_A.jpg: 480x640 (no detections), 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No detection found for image: 237_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/165_A.jpg: 480x640 2 As, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/165_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/71_A.jpg: 480x640 3 As, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/71_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/292_A.jpg: 480x640 3 As, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/292_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/78_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/78_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/272_A.jpg: 480x640 (no detections), 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No detection found for image: 272_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/179_A.jpg: 480x640 3 As, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/179_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/31_A.jpg: 480x640 2 As, 12.1ms\n",
      "Speed: 0.6ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/31_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/2_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/2_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/53_A.jpg: 480x640 2 As, 12.1ms\n",
      "Speed: 0.6ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/53_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/112_A.jpg: 480x640 (no detections), 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No detection found for image: 112_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/54_A.jpg: 480x640 1 A, 12.1ms\n",
      "Speed: 0.6ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/54_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/245_A.jpg: 480x640 (no detections), 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No detection found for image: 245_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/111_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/111_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/223_A.jpg: 480x640 1 A, 12.1ms\n",
      "Speed: 0.6ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/223_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/168_A.jpg: 480x640 2 As, 12.1ms\n",
      "Speed: 0.6ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/168_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/190_A.jpg: 480x640 2 As, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No boxes with confidence > 0.5 for image: 190_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/235_A.jpg: 480x640 (no detections), 12.1ms\n",
      "Speed: 0.6ms preprocess, 12.1ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No detection found for image: 235_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/55_A.jpg: 480x640 1 A, 12.1ms\n",
      "Speed: 0.6ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/55_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/122_A.jpg: 480x640 2 As, 12.2ms\n",
      "Speed: 0.6ms preprocess, 12.2ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/122_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/247_A.jpg: 480x640 1 A, 12.1ms\n",
      "Speed: 0.6ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No boxes with confidence > 0.5 for image: 247_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/8_A.jpg: 480x640 2 As, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/8_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/103_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/103_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/174_A.jpg: 480x640 2 As, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/174_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/260_A.jpg: 480x640 2 As, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/260_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/29_A.jpg: 480x640 2 As, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/29_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/143_A.jpg: 480x640 3 As, 12.1ms\n",
      "Speed: 0.6ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/143_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/42_A.jpg: 480x640 2 As, 12.1ms\n",
      "Speed: 0.6ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/42_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/219_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/219_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/23_A.jpg: 480x640 3 As, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/23_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/19_A.jpg: 480x640 3 As, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/19_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/199_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/199_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/34_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/34_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/104_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/104_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/284_A.jpg: 480x640 1 A, 12.1ms\n",
      "Speed: 0.6ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/284_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/184_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No boxes with confidence > 0.5 for image: 184_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/91_A.jpg: 480x640 2 As, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/91_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/271_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/271_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/5_A.jpg: 480x640 2 As, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/5_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/107_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No boxes with confidence > 0.5 for image: 107_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/146_A.jpg: 480x640 3 As, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No boxes with confidence > 0.5 for image: 146_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/169_A.jpg: 480x640 2 As, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/169_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/167_A.jpg: 480x640 2 As, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/167_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/290_A.jpg: 480x640 1 A, 12.1ms\n",
      "Speed: 0.6ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/290_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/188_A.jpg: 480x640 2 As, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/188_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/84_A.jpg: 480x640 2 As, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/84_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/102_A.jpg: 480x640 (no detections), 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No detection found for image: 102_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/148_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/148_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/62_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/62_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/133_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/133_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/41_A.jpg: 480x640 2 As, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/41_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/222_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/222_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/115_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/115_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/192_A.jpg: 480x640 2 As, 12.1ms\n",
      "Speed: 0.6ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/192_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/225_A.jpg: 480x640 1 A, 12.1ms\n",
      "Speed: 0.6ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No boxes with confidence > 0.5 for image: 225_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/46_A.jpg: 480x640 1 A, 12.1ms\n",
      "Speed: 0.6ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/46_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/156_A.jpg: 480x640 2 As, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/156_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/51_A.jpg: 480x640 2 As, 12.1ms\n",
      "Speed: 0.6ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/51_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/127_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No boxes with confidence > 0.5 for image: 127_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/32_A.jpg: 480x640 2 As, 12.1ms\n",
      "Speed: 0.6ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/32_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/80_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/80_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/202_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/202_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/44_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/44_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/161_A.jpg: 480x640 2 As, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/161_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/171_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "No boxes with confidence > 0.5 for image: 171_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/299_A.jpg: 480x640 2 As, 12.1ms\n",
      "Speed: 0.6ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/299_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/201_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/201_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/52_A.jpg: 480x640 2 As, 12.1ms\n",
      "Speed: 0.6ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/52_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/215_A.jpg: 480x640 1 A, 12.1ms\n",
      "Speed: 0.6ms preprocess, 12.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/215_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/4_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/4_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/220_A.jpg: 480x640 1 A, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/220_A.jpg\n",
      "\n",
      "image 1/1 /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Train_Data/A/269_A.jpg: 480x640 2 As, 12.0ms\n",
      "Speed: 0.6ms preprocess, 12.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Saved image with confidence > 0.5: /home/jai/ML_CPS_PROJECT_1/ml_cps_p1_d2/Project 1 Data 2/Output_Conf_Images_A/269_A.jpg\n"
     ]
    }
   ],
   "source": [
    "# Path to input images\n",
    "input_image_path = \"............./Train_Data/A\"\n",
    "\n",
    "# Path to save images that meet the confidence threshold\n",
    "output_image_path = \"............/Output_Conf_Images_A\"  \n",
    "os.makedirs(output_image_path, exist_ok=True)\n",
    "\n",
    "# Iterate over each image in the input folder\n",
    "for image_file in os.listdir(input_image_path):\n",
    "    image_path = os.path.join(input_image_path, image_file)\n",
    "\n",
    "    # Predict bounding boxes on the image without saving or drawing\n",
    "    results = model(image_path, save=False)\n",
    "\n",
    "    # Get the bounding box with the highest confidence\n",
    "    if len(results[0].boxes) > 0:  # Ensure there is at least one detection\n",
    "        \n",
    "        filtered_boxes = [box for box in results[0].boxes if box.conf > 0.5]\n",
    "\n",
    "        if filtered_boxes:  # If there are any boxes that satisfy the confidence condition\n",
    "            # Save the original image in the output folder\n",
    "            img = cv2.imread(image_path)\n",
    "            output_file_path = os.path.join(output_image_path, image_file)\n",
    "            cv2.imwrite(output_file_path, img)\n",
    "            print(f\"Saved image with confidence > 0.5: {output_file_path}\")\n",
    "        else:\n",
    "            print(f\"No boxes with confidence > 0.5 for image: {image_file}\")\n",
    "    else:\n",
    "        print(f\"No detection found for image: {image_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
